import sqlite3
import numpy as np
import psycopg2
from psycopg2.extras import execute_values
from tqdm import tqdm  # Pasek postƒôpu
from dotenv import load_dotenv
import os

# üîπ Za≈Çaduj zmienne ≈õrodowiskowe z pliku .env
load_dotenv()

# --- KONFIGURACJA SUPABASE (PostgreSQL) ---
DB_NAME = os.getenv('DB_NAME')
DB_USER = os.getenv('DB_USER')
DB_PASSWORD = os.getenv('DB_PASSWORD')
DB_HOST = os.getenv('DB_HOST')
DB_PORT = os.getenv('DB_PORT')
TABLE_NAME = "document_vectors"  # Nazwa tabeli w Supabase

# --- Konfigurcja Vector Space ---
VECTOR_SIZE = 3072  # Rozmiar wektor√≥w dla text-embedding-3-large

# --- Po≈ÇƒÖczenie z lokalnƒÖ bazƒÖ SQLite ---
conn_sqlite = sqlite3.connect("vectors.db")
cursor_sqlite = conn_sqlite.cursor()

# --- Pobranie wszystkich wektor√≥w ---
cursor_sqlite.execute("SELECT filename, text_snippet, vector FROM document_vectors")
rows = cursor_sqlite.fetchall()

# --- Po≈ÇƒÖczenie z bazƒÖ PostgreSQL (Supabase) ---
conn_pg = psycopg2.connect(
    dbname=DB_NAME,
    user=DB_USER,
    password=DB_PASSWORD,
    host=DB_HOST,
    port=DB_PORT
)
cursor_pg = conn_pg.cursor()

# --- Tworzenie tabeli w Supabase (je≈õli nie istnieje) ---
cursor_pg.execute(f"""
CREATE TABLE IF NOT EXISTS {TABLE_NAME} (
    id SERIAL PRIMARY KEY,
    filename TEXT,
    text_snippet TEXT,
    vector VECTOR({VECTOR_SIZE})  -- Obs≈Çuga nowego wymiaru dla text-embedding-3-large
)
""")
conn_pg.commit()

# --- Przygotowanie danych do batch insert ---
data = []
print("üîÑ Pobieranie danych z SQLite...")
for row in tqdm(rows, desc="üìÇ Przetwarzanie wektor√≥w", unit="vec"):
    filename, text_snippet, vector_blob = row

    # Usuniƒôcie NULL (\x00) z tekstu
    text_snippet = text_snippet.replace("\x00", " ") if text_snippet else ""
    
    # Konwersja z SQLite (binary blob) na listƒô float√≥w
    vector = np.frombuffer(vector_blob, dtype=np.float32).tolist()
    
    # Sprawdzenie poprawno≈õci wymiaru
    if len(vector) != VECTOR_SIZE:
        print(f"‚ö†Ô∏è Wektor dla {filename} ma niepoprawny wymiar: {len(vector)}")
        continue  # Pomijamy b≈Çƒôdne dane

    data.append((filename, text_snippet, vector))

if data:
    print("üöÄ Wysy≈Çanie danych do Supabase...")
    query = f"INSERT INTO {TABLE_NAME} (filename, text_snippet, vector) VALUES %s"

    # Dodajemy pasek postƒôpu dla batch insert
    batch_size = 500  # Wstawiamy po 500 rekord√≥w dla optymalizacji
    for i in tqdm(range(0, len(data), batch_size), desc="üì§ Wysy≈Çanie batchy", unit="batch"):
        batch = data[i:i+batch_size]
        execute_values(cursor_pg, query, batch)
        conn_pg.commit()

    print(f"‚úÖ Przes≈Çano {len(data)} wektor√≥w do Supabase!")

# --- Zamkniƒôcie po≈ÇƒÖcze≈Ñ ---
cursor_sqlite.close()
conn_sqlite.close()
cursor_pg.close()
conn_pg.close()

print("üéØ Wszystkie dane zosta≈Çy przes≈Çane do Supabase PostgreSQL!")